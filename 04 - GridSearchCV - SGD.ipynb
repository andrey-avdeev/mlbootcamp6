{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - GridSearchCV - SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_folder = \"models/\"\n",
    "train_data_fn = models_folder+'train_data.pkl'\n",
    "target_fn = models_folder+'target.pkl'\n",
    "test_data_fn = models_folder+'test_data.pkl'\n",
    "\n",
    "weight_multiplier_fn = models_folder+\"weight_multiplier.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "def Load(filename):\n",
    "    if os.path.isfile(filename):\n",
    "        return joblib.load(filename)\n",
    "    \n",
    "def Save(obj, filename):\n",
    "    joblib.dump(obj, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "data = scipy.sparse.load_npz(\"train_sparse_matrix_after_scale.npz\")\n",
    "\n",
    "target = Load(target_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_multiplier = Load(weight_multiplier_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aavdeev/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(data, target.ravel(), train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = {\n",
    "    'loss':['hinge','perceptron'],\n",
    "    'penalty':['l2', 'l1','elasticnet'],\n",
    "    'alpha':[0.0001,0.004,0.02,0.00005],\n",
    "    'l1_ratio':[0.15,0.05,0.4,0.8],\n",
    "    'fit_intercept':[True],\n",
    "    'max_iter':[10,100,200],\n",
    "    'tol':[None,0.0001,0.001,0.01],\n",
    "    'shuffle':[True,False],\n",
    "    'verbose':[0],\n",
    "    'epsilon':[0.1,0.5,0.8],\n",
    "    'n_jobs':[2],\n",
    "    'random_state':[42],\n",
    "    'learning_rate':['optimal','invscaling'],\n",
    "    'eta0':[0.1,0.04,0.01],\n",
    "    'power_t':[0.5,0.9,0.1],\n",
    "    'class_weight':[{0:1,1:1},{0:1,1:weight_multiplier},{0:1,1:1/weight_multiplier}],\n",
    "    'warm_start':[False],\n",
    "    'average':[False,10,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 114 µs, sys: 19 µs, total: 133 µs\n",
      "Wall time: 143 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "\n",
    "clf = RandomizedSearchCV(SGDClassifier(),\n",
    "                   tuned_parameters,\n",
    "                   cv=4,\n",
    "                   n_iter=5,\n",
    "                   n_jobs=7,\n",
    "                   scoring='roc_auc',\n",
    "                   random_state=42,\n",
    "                   verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "[CV] warm_start=False, verbose=0, tol=0.001, shuffle=False, random_state=42, power_t=0.9, penalty=elasticnet, n_jobs=2, max_iter=100, loss=hinge, learning_rate=optimal, l1_ratio=0.05, fit_intercept=True, eta0=0.01, epsilon=0.8, class_weight={0: 1, 1: 1}, average=10, alpha=0.0001 \n",
      "[CV] warm_start=False, verbose=0, tol=0.001, shuffle=False, random_state=42, power_t=0.9, penalty=elasticnet, n_jobs=2, max_iter=100, loss=hinge, learning_rate=optimal, l1_ratio=0.05, fit_intercept=True, eta0=0.01, epsilon=0.8, class_weight={0: 1, 1: 1}, average=10, alpha=0.0001 \n",
      "[CV] warm_start=False, verbose=0, tol=0.001, shuffle=False, random_state=42, power_t=0.9, penalty=elasticnet, n_jobs=2, max_iter=100, loss=hinge, learning_rate=optimal, l1_ratio=0.05, fit_intercept=True, eta0=0.01, epsilon=0.8, class_weight={0: 1, 1: 1}, average=10, alpha=0.0001 \n",
      "[CV] warm_start=False, verbose=0, tol=0.001, shuffle=False, random_state=42, power_t=0.9, penalty=elasticnet, n_jobs=2, max_iter=100, loss=hinge, learning_rate=optimal, l1_ratio=0.05, fit_intercept=True, eta0=0.01, epsilon=0.8, class_weight={0: 1, 1: 1}, average=10, alpha=0.0001 \n",
      "[CV] warm_start=False, verbose=0, tol=0.01, shuffle=True, random_state=42, power_t=0.1, penalty=l1, n_jobs=2, max_iter=10, loss=perceptron, learning_rate=invscaling, l1_ratio=0.15, fit_intercept=True, eta0=0.01, epsilon=0.5, class_weight={0: 1, 1: 1}, average=10, alpha=0.02 \n",
      "[CV] warm_start=False, verbose=0, tol=0.01, shuffle=True, random_state=42, power_t=0.1, penalty=l1, n_jobs=2, max_iter=10, loss=perceptron, learning_rate=invscaling, l1_ratio=0.15, fit_intercept=True, eta0=0.01, epsilon=0.5, class_weight={0: 1, 1: 1}, average=10, alpha=0.02 \n",
      "[CV] warm_start=False, verbose=0, tol=0.01, shuffle=True, random_state=42, power_t=0.1, penalty=l1, n_jobs=2, max_iter=10, loss=perceptron, learning_rate=invscaling, l1_ratio=0.15, fit_intercept=True, eta0=0.01, epsilon=0.5, class_weight={0: 1, 1: 1}, average=10, alpha=0.02 \n",
      "[CV]  warm_start=False, verbose=0, tol=0.01, shuffle=True, random_state=42, power_t=0.1, penalty=l1, n_jobs=2, max_iter=10, loss=perceptron, learning_rate=invscaling, l1_ratio=0.15, fit_intercept=True, eta0=0.01, epsilon=0.5, class_weight={0: 1, 1: 1}, average=10, alpha=0.02, total=  23.6s\n",
      "[CV] warm_start=False, verbose=0, tol=0.01, shuffle=True, random_state=42, power_t=0.1, penalty=l1, n_jobs=2, max_iter=10, loss=perceptron, learning_rate=invscaling, l1_ratio=0.15, fit_intercept=True, eta0=0.01, epsilon=0.5, class_weight={0: 1, 1: 1}, average=10, alpha=0.02 \n",
      "[CV]  warm_start=False, verbose=0, tol=0.01, shuffle=True, random_state=42, power_t=0.1, penalty=l1, n_jobs=2, max_iter=10, loss=perceptron, learning_rate=invscaling, l1_ratio=0.15, fit_intercept=True, eta0=0.01, epsilon=0.5, class_weight={0: 1, 1: 1}, average=10, alpha=0.02, total=  25.8s\n",
      "[CV] warm_start=False, verbose=0, tol=None, shuffle=False, random_state=42, power_t=0.5, penalty=l1, n_jobs=2, max_iter=200, loss=hinge, learning_rate=invscaling, l1_ratio=0.15, fit_intercept=True, eta0=0.01, epsilon=0.1, class_weight={0: 1, 1: 18.951239977624464}, average=10, alpha=0.0001 \n",
      "[CV]  warm_start=False, verbose=0, tol=0.01, shuffle=True, random_state=42, power_t=0.1, penalty=l1, n_jobs=2, max_iter=10, loss=perceptron, learning_rate=invscaling, l1_ratio=0.15, fit_intercept=True, eta0=0.01, epsilon=0.5, class_weight={0: 1, 1: 1}, average=10, alpha=0.02, total=  24.4s\n",
      "[CV] warm_start=False, verbose=0, tol=None, shuffle=False, random_state=42, power_t=0.5, penalty=l1, n_jobs=2, max_iter=200, loss=hinge, learning_rate=invscaling, l1_ratio=0.15, fit_intercept=True, eta0=0.01, epsilon=0.1, class_weight={0: 1, 1: 18.951239977624464}, average=10, alpha=0.0001 \n",
      "[CV]  warm_start=False, verbose=0, tol=0.01, shuffle=True, random_state=42, power_t=0.1, penalty=l1, n_jobs=2, max_iter=10, loss=perceptron, learning_rate=invscaling, l1_ratio=0.15, fit_intercept=True, eta0=0.01, epsilon=0.5, class_weight={0: 1, 1: 1}, average=10, alpha=0.02, total=  27.3s\n",
      "[CV] warm_start=False, verbose=0, tol=None, shuffle=False, random_state=42, power_t=0.5, penalty=l1, n_jobs=2, max_iter=200, loss=hinge, learning_rate=invscaling, l1_ratio=0.15, fit_intercept=True, eta0=0.01, epsilon=0.1, class_weight={0: 1, 1: 18.951239977624464}, average=10, alpha=0.0001 \n",
      "[CV]  warm_start=False, verbose=0, tol=0.001, shuffle=False, random_state=42, power_t=0.9, penalty=elasticnet, n_jobs=2, max_iter=100, loss=hinge, learning_rate=optimal, l1_ratio=0.05, fit_intercept=True, eta0=0.01, epsilon=0.8, class_weight={0: 1, 1: 1}, average=10, alpha=0.0001, total= 5.0min\n",
      "[CV] warm_start=False, verbose=0, tol=None, shuffle=False, random_state=42, power_t=0.5, penalty=l1, n_jobs=2, max_iter=200, loss=hinge, learning_rate=invscaling, l1_ratio=0.15, fit_intercept=True, eta0=0.01, epsilon=0.1, class_weight={0: 1, 1: 18.951239977624464}, average=10, alpha=0.0001 \n",
      "[CV]  warm_start=False, verbose=0, tol=0.001, shuffle=False, random_state=42, power_t=0.9, penalty=elasticnet, n_jobs=2, max_iter=100, loss=hinge, learning_rate=optimal, l1_ratio=0.05, fit_intercept=True, eta0=0.01, epsilon=0.8, class_weight={0: 1, 1: 1}, average=10, alpha=0.0001, total= 5.0min\n",
      "[CV] warm_start=False, verbose=0, tol=0.001, shuffle=True, random_state=42, power_t=0.5, penalty=elasticnet, n_jobs=2, max_iter=200, loss=perceptron, learning_rate=invscaling, l1_ratio=0.8, fit_intercept=True, eta0=0.01, epsilon=0.1, class_weight={0: 1, 1: 0.05276699578395344}, average=100, alpha=0.0001 \n",
      "[CV]  warm_start=False, verbose=0, tol=0.001, shuffle=False, random_state=42, power_t=0.9, penalty=elasticnet, n_jobs=2, max_iter=100, loss=hinge, learning_rate=optimal, l1_ratio=0.05, fit_intercept=True, eta0=0.01, epsilon=0.8, class_weight={0: 1, 1: 1}, average=10, alpha=0.0001, total= 5.4min\n",
      "[CV] warm_start=False, verbose=0, tol=0.001, shuffle=True, random_state=42, power_t=0.5, penalty=elasticnet, n_jobs=2, max_iter=200, loss=perceptron, learning_rate=invscaling, l1_ratio=0.8, fit_intercept=True, eta0=0.01, epsilon=0.1, class_weight={0: 1, 1: 0.05276699578395344}, average=100, alpha=0.0001 \n",
      "[CV]  warm_start=False, verbose=0, tol=0.001, shuffle=False, random_state=42, power_t=0.9, penalty=elasticnet, n_jobs=2, max_iter=100, loss=hinge, learning_rate=optimal, l1_ratio=0.05, fit_intercept=True, eta0=0.01, epsilon=0.8, class_weight={0: 1, 1: 1}, average=10, alpha=0.0001, total= 5.6min\n",
      "[CV] warm_start=False, verbose=0, tol=0.001, shuffle=True, random_state=42, power_t=0.5, penalty=elasticnet, n_jobs=2, max_iter=200, loss=perceptron, learning_rate=invscaling, l1_ratio=0.8, fit_intercept=True, eta0=0.01, epsilon=0.1, class_weight={0: 1, 1: 0.05276699578395344}, average=100, alpha=0.0001 \n",
      "[CV]  warm_start=False, verbose=0, tol=0.001, shuffle=True, random_state=42, power_t=0.5, penalty=elasticnet, n_jobs=2, max_iter=200, loss=perceptron, learning_rate=invscaling, l1_ratio=0.8, fit_intercept=True, eta0=0.01, epsilon=0.1, class_weight={0: 1, 1: 0.05276699578395344}, average=100, alpha=0.0001, total=  51.8s\n",
      "[CV] warm_start=False, verbose=0, tol=0.001, shuffle=True, random_state=42, power_t=0.5, penalty=elasticnet, n_jobs=2, max_iter=200, loss=perceptron, learning_rate=invscaling, l1_ratio=0.8, fit_intercept=True, eta0=0.01, epsilon=0.1, class_weight={0: 1, 1: 0.05276699578395344}, average=100, alpha=0.0001 \n",
      "[CV]  warm_start=False, verbose=0, tol=0.001, shuffle=True, random_state=42, power_t=0.5, penalty=elasticnet, n_jobs=2, max_iter=200, loss=perceptron, learning_rate=invscaling, l1_ratio=0.8, fit_intercept=True, eta0=0.01, epsilon=0.1, class_weight={0: 1, 1: 0.05276699578395344}, average=100, alpha=0.0001, total=  52.9s\n",
      "[CV] warm_start=False, verbose=0, tol=None, shuffle=False, random_state=42, power_t=0.9, penalty=l1, n_jobs=2, max_iter=100, loss=hinge, learning_rate=invscaling, l1_ratio=0.8, fit_intercept=True, eta0=0.04, epsilon=0.5, class_weight={0: 1, 1: 1}, average=10, alpha=0.0001 \n",
      "[CV]  warm_start=False, verbose=0, tol=0.001, shuffle=True, random_state=42, power_t=0.5, penalty=elasticnet, n_jobs=2, max_iter=200, loss=perceptron, learning_rate=invscaling, l1_ratio=0.8, fit_intercept=True, eta0=0.01, epsilon=0.1, class_weight={0: 1, 1: 0.05276699578395344}, average=100, alpha=0.0001, total= 1.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] warm_start=False, verbose=0, tol=None, shuffle=False, random_state=42, power_t=0.9, penalty=l1, n_jobs=2, max_iter=100, loss=hinge, learning_rate=invscaling, l1_ratio=0.8, fit_intercept=True, eta0=0.04, epsilon=0.5, class_weight={0: 1, 1: 1}, average=10, alpha=0.0001 \n",
      "[CV]  warm_start=False, verbose=0, tol=0.001, shuffle=True, random_state=42, power_t=0.5, penalty=elasticnet, n_jobs=2, max_iter=200, loss=perceptron, learning_rate=invscaling, l1_ratio=0.8, fit_intercept=True, eta0=0.01, epsilon=0.1, class_weight={0: 1, 1: 0.05276699578395344}, average=100, alpha=0.0001, total=  52.1s\n",
      "[CV] warm_start=False, verbose=0, tol=None, shuffle=False, random_state=42, power_t=0.9, penalty=l1, n_jobs=2, max_iter=100, loss=hinge, learning_rate=invscaling, l1_ratio=0.8, fit_intercept=True, eta0=0.04, epsilon=0.5, class_weight={0: 1, 1: 1}, average=10, alpha=0.0001 \n",
      "[CV]  warm_start=False, verbose=0, tol=None, shuffle=False, random_state=42, power_t=0.9, penalty=l1, n_jobs=2, max_iter=100, loss=hinge, learning_rate=invscaling, l1_ratio=0.8, fit_intercept=True, eta0=0.04, epsilon=0.5, class_weight={0: 1, 1: 1}, average=10, alpha=0.0001, total=12.6min\n",
      "[CV] warm_start=False, verbose=0, tol=None, shuffle=False, random_state=42, power_t=0.9, penalty=l1, n_jobs=2, max_iter=100, loss=hinge, learning_rate=invscaling, l1_ratio=0.8, fit_intercept=True, eta0=0.04, epsilon=0.5, class_weight={0: 1, 1: 1}, average=10, alpha=0.0001 \n",
      "[CV]  warm_start=False, verbose=0, tol=None, shuffle=False, random_state=42, power_t=0.9, penalty=l1, n_jobs=2, max_iter=100, loss=hinge, learning_rate=invscaling, l1_ratio=0.8, fit_intercept=True, eta0=0.04, epsilon=0.5, class_weight={0: 1, 1: 1}, average=10, alpha=0.0001, total=12.7min\n",
      "[CV]  warm_start=False, verbose=0, tol=None, shuffle=False, random_state=42, power_t=0.9, penalty=l1, n_jobs=2, max_iter=100, loss=hinge, learning_rate=invscaling, l1_ratio=0.8, fit_intercept=True, eta0=0.04, epsilon=0.5, class_weight={0: 1, 1: 1}, average=10, alpha=0.0001, total=12.4min\n",
      "[CV]  warm_start=False, verbose=0, tol=None, shuffle=False, random_state=42, power_t=0.5, penalty=l1, n_jobs=2, max_iter=200, loss=hinge, learning_rate=invscaling, l1_ratio=0.15, fit_intercept=True, eta0=0.01, epsilon=0.1, class_weight={0: 1, 1: 18.951239977624464}, average=10, alpha=0.0001, total=21.8min\n",
      "[CV]  warm_start=False, verbose=0, tol=None, shuffle=False, random_state=42, power_t=0.5, penalty=l1, n_jobs=2, max_iter=200, loss=hinge, learning_rate=invscaling, l1_ratio=0.15, fit_intercept=True, eta0=0.01, epsilon=0.1, class_weight={0: 1, 1: 18.951239977624464}, average=10, alpha=0.0001, total=22.1min\n",
      "[CV]  warm_start=False, verbose=0, tol=None, shuffle=False, random_state=42, power_t=0.5, penalty=l1, n_jobs=2, max_iter=200, loss=hinge, learning_rate=invscaling, l1_ratio=0.15, fit_intercept=True, eta0=0.01, epsilon=0.1, class_weight={0: 1, 1: 18.951239977624464}, average=10, alpha=0.0001, total=22.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  18 out of  20 | elapsed: 23.3min remaining:  2.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  warm_start=False, verbose=0, tol=None, shuffle=False, random_state=42, power_t=0.5, penalty=l1, n_jobs=2, max_iter=200, loss=hinge, learning_rate=invscaling, l1_ratio=0.15, fit_intercept=True, eta0=0.01, epsilon=0.1, class_weight={0: 1, 1: 18.951239977624464}, average=10, alpha=0.0001, total=18.9min\n",
      "[CV]  warm_start=False, verbose=0, tol=None, shuffle=False, random_state=42, power_t=0.9, penalty=l1, n_jobs=2, max_iter=100, loss=hinge, learning_rate=invscaling, l1_ratio=0.8, fit_intercept=True, eta0=0.04, epsilon=0.5, class_weight={0: 1, 1: 1}, average=10, alpha=0.0001, total= 5.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  20 out of  20 | elapsed: 24.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 16s, sys: 1.07 s, total: 7min 17s\n",
      "Wall time: 30min 59s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, error_score='raise',\n",
       "          estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=5, n_jobs=7,\n",
       "          param_distributions={'loss': ['hinge', 'perceptron'], 'penalty': ['l2', 'l1', 'elasticnet'], 'alpha': [0.0001, 0.004, 0.02, 5e-05], 'l1_ratio': [0.15, 0.05, 0.4, 0.8], 'fit_intercept': [True], 'max_iter': [10, 100, 200], 'tol': [None, 0.0001, 0.001, 0.01], 'shuffle': [True, False], 'verbose': [0], '...1239977624464}, {0: 1, 1: 0.05276699578395344}], 'warm_start': [False], 'average': [False, 10, 100]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.578 (std: 0.006)\n",
      "Parameters: {'warm_start': False, 'verbose': 0, 'tol': None, 'shuffle': False, 'random_state': 42, 'power_t': 0.5, 'penalty': 'l1', 'n_jobs': 2, 'max_iter': 200, 'loss': 'hinge', 'learning_rate': 'invscaling', 'l1_ratio': 0.15, 'fit_intercept': True, 'eta0': 0.01, 'epsilon': 0.1, 'class_weight': {0: 1, 1: 18.951239977624464}, 'average': 10, 'alpha': 0.0001}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.542 (std: 0.016)\n",
      "Parameters: {'warm_start': False, 'verbose': 0, 'tol': None, 'shuffle': False, 'random_state': 42, 'power_t': 0.9, 'penalty': 'l1', 'n_jobs': 2, 'max_iter': 100, 'loss': 'hinge', 'learning_rate': 'invscaling', 'l1_ratio': 0.8, 'fit_intercept': True, 'eta0': 0.04, 'epsilon': 0.5, 'class_weight': {0: 1, 1: 1}, 'average': 10, 'alpha': 0.0001}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.539 (std: 0.006)\n",
      "Parameters: {'warm_start': False, 'verbose': 0, 'tol': 0.001, 'shuffle': False, 'random_state': 42, 'power_t': 0.9, 'penalty': 'elasticnet', 'n_jobs': 2, 'max_iter': 100, 'loss': 'hinge', 'learning_rate': 'optimal', 'l1_ratio': 0.05, 'fit_intercept': True, 'eta0': 0.01, 'epsilon': 0.8, 'class_weight': {0: 1, 1: 1}, 'average': 10, 'alpha': 0.0001}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"RandomizedSearchCV\")\n",
    "report(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = clf.best_params_\n",
    "# params = {'warm_start': False, 'verbose': 0, 'tol': None, 'shuffle': False, 'random_state': 42, 'power_t': 0.5, 'penalty': 'l1', 'n_jobs': 2, 'max_iter': 200, 'loss': 'hinge', 'learning_rate': 'invscaling', 'l1_ratio': 0.15, 'fit_intercept': True, 'eta0': 0.01, 'epsilon': 0.1, 'class_weight': {0: 1, 1: 18.951239977624464}, 'average': 10, 'alpha': 0.0001}\n",
    "params['n_jobs']=-1\n",
    "params['verbose']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 13.60, NNZs: 33570, Bias: 0.001022, T: 342395, Avg. loss: 3.820180\n",
      "Total training time: 1.78 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 12.99, NNZs: 33430, Bias: 0.001310, T: 684790, Avg. loss: 2.550982\n",
      "Total training time: 3.54 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 12.62, NNZs: 33266, Bias: 0.001563, T: 1027185, Avg. loss: 2.045418\n",
      "Total training time: 5.41 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 12.37, NNZs: 33013, Bias: 0.001826, T: 1369580, Avg. loss: 1.784594\n",
      "Total training time: 7.25 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.19, NNZs: 32799, Bias: 0.002072, T: 1711975, Avg. loss: 1.618152\n",
      "Total training time: 9.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 12.05, NNZs: 32650, Bias: 0.002287, T: 2054370, Avg. loss: 1.495988\n",
      "Total training time: 10.87 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 11.94, NNZs: 32506, Bias: 0.002485, T: 2396765, Avg. loss: 1.415385\n",
      "Total training time: 12.66 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 11.84, NNZs: 32370, Bias: 0.002659, T: 2739160, Avg. loss: 1.357492\n",
      "Total training time: 14.56 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 11.77, NNZs: 32281, Bias: 0.002824, T: 3081555, Avg. loss: 1.303368\n",
      "Total training time: 16.34 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 11.70, NNZs: 32162, Bias: 0.002967, T: 3423950, Avg. loss: 1.262439\n",
      "Total training time: 18.10 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 11.64, NNZs: 32076, Bias: 0.003111, T: 3766345, Avg. loss: 1.227083\n",
      "Total training time: 20.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 11.58, NNZs: 31979, Bias: 0.003246, T: 4108740, Avg. loss: 1.202162\n",
      "Total training time: 22.08 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 11.53, NNZs: 31918, Bias: 0.003374, T: 4451135, Avg. loss: 1.174499\n",
      "Total training time: 24.12 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 11.49, NNZs: 31883, Bias: 0.003504, T: 4793530, Avg. loss: 1.155245\n",
      "Total training time: 26.09 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 11.45, NNZs: 31795, Bias: 0.003622, T: 5135925, Avg. loss: 1.131072\n",
      "Total training time: 27.98 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 11.41, NNZs: 31808, Bias: 0.003734, T: 5478320, Avg. loss: 1.110713\n",
      "Total training time: 29.90 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 11.38, NNZs: 31719, Bias: 0.003844, T: 5820715, Avg. loss: 1.098824\n",
      "Total training time: 31.93 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 11.35, NNZs: 31638, Bias: 0.003941, T: 6163110, Avg. loss: 1.083876\n",
      "Total training time: 33.85 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 11.32, NNZs: 31563, Bias: 0.004054, T: 6505505, Avg. loss: 1.069188\n",
      "Total training time: 36.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 11.29, NNZs: 31512, Bias: 0.004153, T: 6847900, Avg. loss: 1.055905\n",
      "Total training time: 37.99 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 11.27, NNZs: 31478, Bias: 0.004257, T: 7190295, Avg. loss: 1.045007\n",
      "Total training time: 39.94 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 11.25, NNZs: 31417, Bias: 0.004346, T: 7532690, Avg. loss: 1.034752\n",
      "Total training time: 41.75 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 11.22, NNZs: 31407, Bias: 0.004444, T: 7875085, Avg. loss: 1.024999\n",
      "Total training time: 43.61 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 11.20, NNZs: 31351, Bias: 0.004542, T: 8217480, Avg. loss: 1.015678\n",
      "Total training time: 45.50 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 11.18, NNZs: 31343, Bias: 0.004634, T: 8559875, Avg. loss: 1.006101\n",
      "Total training time: 47.35 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 11.16, NNZs: 31290, Bias: 0.004717, T: 8902270, Avg. loss: 1.000709\n",
      "Total training time: 49.19 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 11.15, NNZs: 31307, Bias: 0.004815, T: 9244665, Avg. loss: 0.992643\n",
      "Total training time: 51.02 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 11.13, NNZs: 31248, Bias: 0.004896, T: 9587060, Avg. loss: 0.987639\n",
      "Total training time: 52.93 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 11.12, NNZs: 31204, Bias: 0.004981, T: 9929455, Avg. loss: 0.980703\n",
      "Total training time: 54.76 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 11.10, NNZs: 31198, Bias: 0.005058, T: 10271850, Avg. loss: 0.973790\n",
      "Total training time: 56.63 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 11.09, NNZs: 31170, Bias: 0.005135, T: 10614245, Avg. loss: 0.968528\n",
      "Total training time: 58.53 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 11.07, NNZs: 31163, Bias: 0.005215, T: 10956640, Avg. loss: 0.961668\n",
      "Total training time: 60.51 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 11.06, NNZs: 31075, Bias: 0.005298, T: 11299035, Avg. loss: 0.957963\n",
      "Total training time: 62.48 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 11.05, NNZs: 31063, Bias: 0.005371, T: 11641430, Avg. loss: 0.951282\n",
      "Total training time: 64.42 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 11.03, NNZs: 30985, Bias: 0.005449, T: 11983825, Avg. loss: 0.949317\n",
      "Total training time: 66.27 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 11.02, NNZs: 30964, Bias: 0.005519, T: 12326220, Avg. loss: 0.945691\n",
      "Total training time: 68.46 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 11.01, NNZs: 30973, Bias: 0.005587, T: 12668615, Avg. loss: 0.940113\n",
      "Total training time: 70.37 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 11.00, NNZs: 30938, Bias: 0.005656, T: 13011010, Avg. loss: 0.937247\n",
      "Total training time: 72.34 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 10.99, NNZs: 30909, Bias: 0.005730, T: 13353405, Avg. loss: 0.932666\n",
      "Total training time: 74.63 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 10.98, NNZs: 30863, Bias: 0.005794, T: 13695800, Avg. loss: 0.929347\n",
      "Total training time: 76.59 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 10.97, NNZs: 30854, Bias: 0.005866, T: 14038195, Avg. loss: 0.925261\n",
      "Total training time: 78.53 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 10.96, NNZs: 30831, Bias: 0.005929, T: 14380590, Avg. loss: 0.920237\n",
      "Total training time: 80.39 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 10.95, NNZs: 30787, Bias: 0.005993, T: 14722985, Avg. loss: 0.919850\n",
      "Total training time: 82.21 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 10.94, NNZs: 30756, Bias: 0.006056, T: 15065380, Avg. loss: 0.916338\n",
      "Total training time: 84.06 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 10.93, NNZs: 30740, Bias: 0.006122, T: 15407775, Avg. loss: 0.914787\n",
      "Total training time: 85.97 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 10.93, NNZs: 30685, Bias: 0.006187, T: 15750170, Avg. loss: 0.910243\n",
      "Total training time: 87.86 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 10.92, NNZs: 30679, Bias: 0.006251, T: 16092565, Avg. loss: 0.907423\n",
      "Total training time: 89.75 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 10.91, NNZs: 30665, Bias: 0.006315, T: 16434960, Avg. loss: 0.904541\n",
      "Total training time: 91.66 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 10.90, NNZs: 30621, Bias: 0.006378, T: 16777355, Avg. loss: 0.902859\n",
      "Total training time: 93.54 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 10.90, NNZs: 30590, Bias: 0.006440, T: 17119750, Avg. loss: 0.900171\n",
      "Total training time: 95.57 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 10.89, NNZs: 30570, Bias: 0.006498, T: 17462145, Avg. loss: 0.898723\n",
      "Total training time: 97.59 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 10.88, NNZs: 30553, Bias: 0.006558, T: 17804540, Avg. loss: 0.895426\n",
      "Total training time: 99.48 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 10.88, NNZs: 30524, Bias: 0.006614, T: 18146935, Avg. loss: 0.894554\n",
      "Total training time: 101.34 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 10.87, NNZs: 30536, Bias: 0.006675, T: 18489330, Avg. loss: 0.890652\n",
      "Total training time: 103.20 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 10.86, NNZs: 30494, Bias: 0.006733, T: 18831725, Avg. loss: 0.890880\n",
      "Total training time: 105.08 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 10.86, NNZs: 30499, Bias: 0.006800, T: 19174120, Avg. loss: 0.885843\n",
      "Total training time: 106.97 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 10.85, NNZs: 30432, Bias: 0.006853, T: 19516515, Avg. loss: 0.883617\n",
      "Total training time: 108.84 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 10.85, NNZs: 30440, Bias: 0.006904, T: 19858910, Avg. loss: 0.881657\n",
      "Total training time: 110.75 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 10.84, NNZs: 30401, Bias: 0.006961, T: 20201305, Avg. loss: 0.882825\n",
      "Total training time: 112.74 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 10.83, NNZs: 30364, Bias: 0.007012, T: 20543700, Avg. loss: 0.877924\n",
      "Total training time: 114.56 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 10.83, NNZs: 30353, Bias: 0.007072, T: 20886095, Avg. loss: 0.877710\n",
      "Total training time: 116.38 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 10.82, NNZs: 30366, Bias: 0.007122, T: 21228490, Avg. loss: 0.876748\n",
      "Total training time: 118.19 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 10.82, NNZs: 30345, Bias: 0.007170, T: 21570885, Avg. loss: 0.873943\n",
      "Total training time: 120.03 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 10.81, NNZs: 30320, Bias: 0.007228, T: 21913280, Avg. loss: 0.873102\n",
      "Total training time: 121.93 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 10.81, NNZs: 30265, Bias: 0.007278, T: 22255675, Avg. loss: 0.871699\n",
      "Total training time: 123.80 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 10.81, NNZs: 30256, Bias: 0.007330, T: 22598070, Avg. loss: 0.869189\n",
      "Total training time: 125.70 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 10.80, NNZs: 30232, Bias: 0.007382, T: 22940465, Avg. loss: 0.867237\n",
      "Total training time: 127.54 seconds.\n",
      "-- Epoch 68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 10.80, NNZs: 30209, Bias: 0.007430, T: 23282860, Avg. loss: 0.866477\n",
      "Total training time: 129.37 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 10.79, NNZs: 30179, Bias: 0.007479, T: 23625255, Avg. loss: 0.865820\n",
      "Total training time: 131.18 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 10.79, NNZs: 30191, Bias: 0.007537, T: 23967650, Avg. loss: 0.864207\n",
      "Total training time: 133.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 10.78, NNZs: 30166, Bias: 0.007587, T: 24310045, Avg. loss: 0.861669\n",
      "Total training time: 134.81 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 10.78, NNZs: 30121, Bias: 0.007635, T: 24652440, Avg. loss: 0.860136\n",
      "Total training time: 136.67 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 10.78, NNZs: 30114, Bias: 0.007686, T: 24994835, Avg. loss: 0.859384\n",
      "Total training time: 138.49 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 10.77, NNZs: 30118, Bias: 0.007734, T: 25337230, Avg. loss: 0.858615\n",
      "Total training time: 140.32 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 10.77, NNZs: 30086, Bias: 0.007786, T: 25679625, Avg. loss: 0.856428\n",
      "Total training time: 142.23 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 10.76, NNZs: 30058, Bias: 0.007831, T: 26022020, Avg. loss: 0.855075\n",
      "Total training time: 144.07 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 10.76, NNZs: 30065, Bias: 0.007879, T: 26364415, Avg. loss: 0.855107\n",
      "Total training time: 145.97 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 10.76, NNZs: 30064, Bias: 0.007925, T: 26706810, Avg. loss: 0.852275\n",
      "Total training time: 147.79 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 10.75, NNZs: 30019, Bias: 0.007969, T: 27049205, Avg. loss: 0.852078\n",
      "Total training time: 149.60 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 10.75, NNZs: 29993, Bias: 0.008023, T: 27391600, Avg. loss: 0.850879\n",
      "Total training time: 151.48 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 10.75, NNZs: 30004, Bias: 0.008069, T: 27733995, Avg. loss: 0.849064\n",
      "Total training time: 153.39 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 10.74, NNZs: 29966, Bias: 0.008113, T: 28076390, Avg. loss: 0.848668\n",
      "Total training time: 155.26 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 10.74, NNZs: 29936, Bias: 0.008156, T: 28418785, Avg. loss: 0.848257\n",
      "Total training time: 157.26 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 10.74, NNZs: 29914, Bias: 0.008201, T: 28761180, Avg. loss: 0.847155\n",
      "Total training time: 159.13 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 10.74, NNZs: 29921, Bias: 0.008247, T: 29103575, Avg. loss: 0.845778\n",
      "Total training time: 161.13 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 10.73, NNZs: 29904, Bias: 0.008291, T: 29445970, Avg. loss: 0.844873\n",
      "Total training time: 163.13 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 10.73, NNZs: 29868, Bias: 0.008335, T: 29788365, Avg. loss: 0.843091\n",
      "Total training time: 165.04 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 10.73, NNZs: 29893, Bias: 0.008386, T: 30130760, Avg. loss: 0.841079\n",
      "Total training time: 166.88 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 10.72, NNZs: 29878, Bias: 0.008429, T: 30473155, Avg. loss: 0.841136\n",
      "Total training time: 168.72 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 10.72, NNZs: 29845, Bias: 0.008471, T: 30815550, Avg. loss: 0.840283\n",
      "Total training time: 170.53 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 10.72, NNZs: 29829, Bias: 0.008516, T: 31157945, Avg. loss: 0.838480\n",
      "Total training time: 172.38 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 10.72, NNZs: 29838, Bias: 0.008556, T: 31500340, Avg. loss: 0.838762\n",
      "Total training time: 174.19 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 10.71, NNZs: 29818, Bias: 0.008596, T: 31842735, Avg. loss: 0.836622\n",
      "Total training time: 176.01 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 10.71, NNZs: 29760, Bias: 0.008642, T: 32185130, Avg. loss: 0.836288\n",
      "Total training time: 177.82 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 10.71, NNZs: 29761, Bias: 0.008682, T: 32527525, Avg. loss: 0.835042\n",
      "Total training time: 179.63 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 10.71, NNZs: 29768, Bias: 0.008722, T: 32869920, Avg. loss: 0.834713\n",
      "Total training time: 181.44 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 10.71, NNZs: 29735, Bias: 0.008766, T: 33212315, Avg. loss: 0.833342\n",
      "Total training time: 183.25 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 10.70, NNZs: 29714, Bias: 0.008809, T: 33554710, Avg. loss: 0.832442\n",
      "Total training time: 185.06 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 10.70, NNZs: 29701, Bias: 0.008850, T: 33897105, Avg. loss: 0.830952\n",
      "Total training time: 186.87 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 10.70, NNZs: 29664, Bias: 0.008893, T: 34239500, Avg. loss: 0.830285\n",
      "Total training time: 188.68 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 10.70, NNZs: 29664, Bias: 0.008933, T: 34581895, Avg. loss: 0.829973\n",
      "Total training time: 190.49 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 10.69, NNZs: 29687, Bias: 0.008975, T: 34924290, Avg. loss: 0.829415\n",
      "Total training time: 192.29 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 10.69, NNZs: 29650, Bias: 0.009013, T: 35266685, Avg. loss: 0.828429\n",
      "Total training time: 194.10 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 10.69, NNZs: 29615, Bias: 0.009055, T: 35609080, Avg. loss: 0.827635\n",
      "Total training time: 195.89 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 10.69, NNZs: 29612, Bias: 0.009096, T: 35951475, Avg. loss: 0.828156\n",
      "Total training time: 197.69 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 10.69, NNZs: 29594, Bias: 0.009134, T: 36293870, Avg. loss: 0.826892\n",
      "Total training time: 199.49 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 10.68, NNZs: 29576, Bias: 0.009175, T: 36636265, Avg. loss: 0.825642\n",
      "Total training time: 201.29 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 10.68, NNZs: 29588, Bias: 0.009214, T: 36978660, Avg. loss: 0.824589\n",
      "Total training time: 203.11 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 10.68, NNZs: 29570, Bias: 0.009255, T: 37321055, Avg. loss: 0.824014\n",
      "Total training time: 204.93 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 10.68, NNZs: 29558, Bias: 0.009293, T: 37663450, Avg. loss: 0.824374\n",
      "Total training time: 206.72 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 10.68, NNZs: 29552, Bias: 0.009332, T: 38005845, Avg. loss: 0.823306\n",
      "Total training time: 208.54 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 10.68, NNZs: 29527, Bias: 0.009374, T: 38348240, Avg. loss: 0.822066\n",
      "Total training time: 210.60 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 10.67, NNZs: 29514, Bias: 0.009407, T: 38690635, Avg. loss: 0.822355\n",
      "Total training time: 212.43 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 10.67, NNZs: 29502, Bias: 0.009450, T: 39033030, Avg. loss: 0.821021\n",
      "Total training time: 214.23 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 10.67, NNZs: 29467, Bias: 0.009486, T: 39375425, Avg. loss: 0.820860\n",
      "Total training time: 216.01 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 10.67, NNZs: 29471, Bias: 0.009524, T: 39717820, Avg. loss: 0.819935\n",
      "Total training time: 217.80 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 10.67, NNZs: 29463, Bias: 0.009559, T: 40060215, Avg. loss: 0.818091\n",
      "Total training time: 219.58 seconds.\n",
      "-- Epoch 118\n",
      "Norm: 10.67, NNZs: 29443, Bias: 0.009598, T: 40402610, Avg. loss: 0.818009\n",
      "Total training time: 221.37 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 10.67, NNZs: 29435, Bias: 0.009633, T: 40745005, Avg. loss: 0.816842\n",
      "Total training time: 223.16 seconds.\n",
      "-- Epoch 120\n",
      "Norm: 10.66, NNZs: 29406, Bias: 0.009669, T: 41087400, Avg. loss: 0.818305\n",
      "Total training time: 224.96 seconds.\n",
      "-- Epoch 121\n",
      "Norm: 10.66, NNZs: 29384, Bias: 0.009711, T: 41429795, Avg. loss: 0.815856\n",
      "Total training time: 226.74 seconds.\n",
      "-- Epoch 122\n",
      "Norm: 10.66, NNZs: 29353, Bias: 0.009747, T: 41772190, Avg. loss: 0.816983\n",
      "Total training time: 228.54 seconds.\n",
      "-- Epoch 123\n",
      "Norm: 10.66, NNZs: 29367, Bias: 0.009785, T: 42114585, Avg. loss: 0.814923\n",
      "Total training time: 230.33 seconds.\n",
      "-- Epoch 124\n",
      "Norm: 10.66, NNZs: 29356, Bias: 0.009823, T: 42456980, Avg. loss: 0.815063\n",
      "Total training time: 232.13 seconds.\n",
      "-- Epoch 125\n",
      "Norm: 10.66, NNZs: 29352, Bias: 0.009856, T: 42799375, Avg. loss: 0.814480\n",
      "Total training time: 233.92 seconds.\n",
      "-- Epoch 126\n",
      "Norm: 10.66, NNZs: 29320, Bias: 0.009896, T: 43141770, Avg. loss: 0.813529\n",
      "Total training time: 235.73 seconds.\n",
      "-- Epoch 127\n",
      "Norm: 10.66, NNZs: 29347, Bias: 0.009930, T: 43484165, Avg. loss: 0.812789\n",
      "Total training time: 237.53 seconds.\n",
      "-- Epoch 128\n",
      "Norm: 10.65, NNZs: 29324, Bias: 0.009969, T: 43826560, Avg. loss: 0.812801\n",
      "Total training time: 239.33 seconds.\n",
      "-- Epoch 129\n",
      "Norm: 10.65, NNZs: 29290, Bias: 0.010003, T: 44168955, Avg. loss: 0.811284\n",
      "Total training time: 241.14 seconds.\n",
      "-- Epoch 130\n",
      "Norm: 10.65, NNZs: 29278, Bias: 0.010038, T: 44511350, Avg. loss: 0.811395\n",
      "Total training time: 242.94 seconds.\n",
      "-- Epoch 131\n",
      "Norm: 10.65, NNZs: 29268, Bias: 0.010074, T: 44853745, Avg. loss: 0.809772\n",
      "Total training time: 244.83 seconds.\n",
      "-- Epoch 132\n",
      "Norm: 10.65, NNZs: 29287, Bias: 0.010108, T: 45196140, Avg. loss: 0.810784\n",
      "Total training time: 246.76 seconds.\n",
      "-- Epoch 133\n",
      "Norm: 10.65, NNZs: 29269, Bias: 0.010143, T: 45538535, Avg. loss: 0.809721\n",
      "Total training time: 248.62 seconds.\n",
      "-- Epoch 134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 10.65, NNZs: 29220, Bias: 0.010181, T: 45880930, Avg. loss: 0.808821\n",
      "Total training time: 250.43 seconds.\n",
      "-- Epoch 135\n",
      "Norm: 10.65, NNZs: 29246, Bias: 0.010214, T: 46223325, Avg. loss: 0.808896\n",
      "Total training time: 252.23 seconds.\n",
      "-- Epoch 136\n",
      "Norm: 10.65, NNZs: 29200, Bias: 0.010246, T: 46565720, Avg. loss: 0.808266\n",
      "Total training time: 254.03 seconds.\n",
      "-- Epoch 137\n",
      "Norm: 10.64, NNZs: 29187, Bias: 0.010281, T: 46908115, Avg. loss: 0.807744\n",
      "Total training time: 255.83 seconds.\n",
      "-- Epoch 138\n",
      "Norm: 10.64, NNZs: 29197, Bias: 0.010318, T: 47250510, Avg. loss: 0.805712\n",
      "Total training time: 257.63 seconds.\n",
      "-- Epoch 139\n",
      "Norm: 10.64, NNZs: 29175, Bias: 0.010351, T: 47592905, Avg. loss: 0.806580\n",
      "Total training time: 259.43 seconds.\n",
      "-- Epoch 140\n",
      "Norm: 10.64, NNZs: 29170, Bias: 0.010388, T: 47935300, Avg. loss: 0.806587\n",
      "Total training time: 261.23 seconds.\n",
      "-- Epoch 141\n",
      "Norm: 10.64, NNZs: 29177, Bias: 0.010419, T: 48277695, Avg. loss: 0.805847\n",
      "Total training time: 263.04 seconds.\n",
      "-- Epoch 142\n",
      "Norm: 10.64, NNZs: 29159, Bias: 0.010454, T: 48620090, Avg. loss: 0.804413\n",
      "Total training time: 264.84 seconds.\n",
      "-- Epoch 143\n",
      "Norm: 10.64, NNZs: 29151, Bias: 0.010487, T: 48962485, Avg. loss: 0.805163\n",
      "Total training time: 266.66 seconds.\n",
      "-- Epoch 144\n",
      "Norm: 10.64, NNZs: 29136, Bias: 0.010522, T: 49304880, Avg. loss: 0.804428\n",
      "Total training time: 268.47 seconds.\n",
      "-- Epoch 145\n",
      "Norm: 10.64, NNZs: 29124, Bias: 0.010556, T: 49647275, Avg. loss: 0.803375\n",
      "Total training time: 270.28 seconds.\n",
      "-- Epoch 146\n",
      "Norm: 10.64, NNZs: 29081, Bias: 0.010589, T: 49989670, Avg. loss: 0.803175\n",
      "Total training time: 272.09 seconds.\n",
      "-- Epoch 147\n",
      "Norm: 10.64, NNZs: 29080, Bias: 0.010626, T: 50332065, Avg. loss: 0.802927\n",
      "Total training time: 273.90 seconds.\n",
      "-- Epoch 148\n",
      "Norm: 10.64, NNZs: 29092, Bias: 0.010658, T: 50674460, Avg. loss: 0.802744\n",
      "Total training time: 275.70 seconds.\n",
      "-- Epoch 149\n",
      "Norm: 10.64, NNZs: 29077, Bias: 0.010692, T: 51016855, Avg. loss: 0.801453\n",
      "Total training time: 277.51 seconds.\n",
      "-- Epoch 150\n",
      "Norm: 10.63, NNZs: 29080, Bias: 0.010726, T: 51359250, Avg. loss: 0.801043\n",
      "Total training time: 279.32 seconds.\n",
      "-- Epoch 151\n",
      "Norm: 10.63, NNZs: 29067, Bias: 0.010761, T: 51701645, Avg. loss: 0.801699\n",
      "Total training time: 281.12 seconds.\n",
      "-- Epoch 152\n",
      "Norm: 10.63, NNZs: 29056, Bias: 0.010789, T: 52044040, Avg. loss: 0.799680\n",
      "Total training time: 282.93 seconds.\n",
      "-- Epoch 153\n",
      "Norm: 10.63, NNZs: 29053, Bias: 0.010825, T: 52386435, Avg. loss: 0.800179\n",
      "Total training time: 284.74 seconds.\n",
      "-- Epoch 154\n",
      "Norm: 10.63, NNZs: 29029, Bias: 0.010855, T: 52728830, Avg. loss: 0.798808\n",
      "Total training time: 286.54 seconds.\n",
      "-- Epoch 155\n",
      "Norm: 10.63, NNZs: 29022, Bias: 0.010886, T: 53071225, Avg. loss: 0.798624\n",
      "Total training time: 288.35 seconds.\n",
      "-- Epoch 156\n",
      "Norm: 10.63, NNZs: 29022, Bias: 0.010921, T: 53413620, Avg. loss: 0.797745\n",
      "Total training time: 290.16 seconds.\n",
      "-- Epoch 157\n",
      "Norm: 10.63, NNZs: 29005, Bias: 0.010953, T: 53756015, Avg. loss: 0.799545\n",
      "Total training time: 291.96 seconds.\n",
      "-- Epoch 158\n",
      "Norm: 10.63, NNZs: 28998, Bias: 0.010981, T: 54098410, Avg. loss: 0.798367\n",
      "Total training time: 293.77 seconds.\n",
      "-- Epoch 159\n",
      "Norm: 10.63, NNZs: 28993, Bias: 0.011015, T: 54440805, Avg. loss: 0.796734\n",
      "Total training time: 295.74 seconds.\n",
      "-- Epoch 160\n",
      "Norm: 10.63, NNZs: 28978, Bias: 0.011048, T: 54783200, Avg. loss: 0.796856\n",
      "Total training time: 297.60 seconds.\n",
      "-- Epoch 161\n",
      "Norm: 10.63, NNZs: 28972, Bias: 0.011078, T: 55125595, Avg. loss: 0.796534\n",
      "Total training time: 299.46 seconds.\n",
      "-- Epoch 162\n",
      "Norm: 10.63, NNZs: 28966, Bias: 0.011112, T: 55467990, Avg. loss: 0.796274\n",
      "Total training time: 301.30 seconds.\n",
      "-- Epoch 163\n",
      "Norm: 10.63, NNZs: 28965, Bias: 0.011141, T: 55810385, Avg. loss: 0.795777\n",
      "Total training time: 303.15 seconds.\n",
      "-- Epoch 164\n",
      "Norm: 10.63, NNZs: 28956, Bias: 0.011173, T: 56152780, Avg. loss: 0.795264\n",
      "Total training time: 304.96 seconds.\n",
      "-- Epoch 165\n",
      "Norm: 10.63, NNZs: 28943, Bias: 0.011205, T: 56495175, Avg. loss: 0.795038\n",
      "Total training time: 306.76 seconds.\n",
      "-- Epoch 166\n",
      "Norm: 10.63, NNZs: 28929, Bias: 0.011234, T: 56837570, Avg. loss: 0.795728\n",
      "Total training time: 308.57 seconds.\n",
      "-- Epoch 167\n",
      "Norm: 10.62, NNZs: 28898, Bias: 0.011266, T: 57179965, Avg. loss: 0.793027\n",
      "Total training time: 310.37 seconds.\n",
      "-- Epoch 168\n",
      "Norm: 10.62, NNZs: 28905, Bias: 0.011296, T: 57522360, Avg. loss: 0.794247\n",
      "Total training time: 312.18 seconds.\n",
      "-- Epoch 169\n",
      "Norm: 10.62, NNZs: 28878, Bias: 0.011330, T: 57864755, Avg. loss: 0.794201\n",
      "Total training time: 314.04 seconds.\n",
      "-- Epoch 170\n",
      "Norm: 10.62, NNZs: 28872, Bias: 0.011358, T: 58207150, Avg. loss: 0.794314\n",
      "Total training time: 315.88 seconds.\n",
      "-- Epoch 171\n",
      "Norm: 10.62, NNZs: 28877, Bias: 0.011391, T: 58549545, Avg. loss: 0.793496\n",
      "Total training time: 318.03 seconds.\n",
      "-- Epoch 172\n",
      "Norm: 10.62, NNZs: 28864, Bias: 0.011420, T: 58891940, Avg. loss: 0.793267\n",
      "Total training time: 319.96 seconds.\n",
      "-- Epoch 173\n",
      "Norm: 10.62, NNZs: 28844, Bias: 0.011450, T: 59234335, Avg. loss: 0.793077\n",
      "Total training time: 321.77 seconds.\n",
      "-- Epoch 174\n",
      "Norm: 10.62, NNZs: 28829, Bias: 0.011479, T: 59576730, Avg. loss: 0.791722\n",
      "Total training time: 323.61 seconds.\n",
      "-- Epoch 175\n",
      "Norm: 10.62, NNZs: 28862, Bias: 0.011511, T: 59919125, Avg. loss: 0.792229\n",
      "Total training time: 325.60 seconds.\n",
      "-- Epoch 176\n",
      "Norm: 10.62, NNZs: 28838, Bias: 0.011542, T: 60261520, Avg. loss: 0.790849\n",
      "Total training time: 327.54 seconds.\n",
      "-- Epoch 177\n",
      "Norm: 10.62, NNZs: 28836, Bias: 0.011573, T: 60603915, Avg. loss: 0.790530\n",
      "Total training time: 329.43 seconds.\n",
      "-- Epoch 178\n",
      "Norm: 10.62, NNZs: 28809, Bias: 0.011603, T: 60946310, Avg. loss: 0.790515\n",
      "Total training time: 331.34 seconds.\n",
      "-- Epoch 179\n",
      "Norm: 10.62, NNZs: 28789, Bias: 0.011635, T: 61288705, Avg. loss: 0.789887\n",
      "Total training time: 333.18 seconds.\n",
      "-- Epoch 180\n",
      "Norm: 10.62, NNZs: 28826, Bias: 0.011663, T: 61631100, Avg. loss: 0.789054\n",
      "Total training time: 335.08 seconds.\n",
      "-- Epoch 181\n",
      "Norm: 10.62, NNZs: 28816, Bias: 0.011691, T: 61973495, Avg. loss: 0.789967\n",
      "Total training time: 336.99 seconds.\n",
      "-- Epoch 182\n",
      "Norm: 10.62, NNZs: 28786, Bias: 0.011722, T: 62315890, Avg. loss: 0.789854\n",
      "Total training time: 338.95 seconds.\n",
      "-- Epoch 183\n",
      "Norm: 10.62, NNZs: 28756, Bias: 0.011753, T: 62658285, Avg. loss: 0.789351\n",
      "Total training time: 340.85 seconds.\n",
      "-- Epoch 184\n",
      "Norm: 10.62, NNZs: 28740, Bias: 0.011781, T: 63000680, Avg. loss: 0.789022\n",
      "Total training time: 342.86 seconds.\n",
      "-- Epoch 185\n",
      "Norm: 10.62, NNZs: 28740, Bias: 0.011808, T: 63343075, Avg. loss: 0.787742\n",
      "Total training time: 344.67 seconds.\n",
      "-- Epoch 186\n",
      "Norm: 10.62, NNZs: 28731, Bias: 0.011840, T: 63685470, Avg. loss: 0.787906\n",
      "Total training time: 346.48 seconds.\n",
      "-- Epoch 187\n",
      "Norm: 10.62, NNZs: 28750, Bias: 0.011869, T: 64027865, Avg. loss: 0.787368\n",
      "Total training time: 348.52 seconds.\n",
      "-- Epoch 188\n",
      "Norm: 10.62, NNZs: 28729, Bias: 0.011900, T: 64370260, Avg. loss: 0.787228\n",
      "Total training time: 350.43 seconds.\n",
      "-- Epoch 189\n",
      "Norm: 10.62, NNZs: 28699, Bias: 0.011928, T: 64712655, Avg. loss: 0.787425\n",
      "Total training time: 352.25 seconds.\n",
      "-- Epoch 190\n",
      "Norm: 10.62, NNZs: 28696, Bias: 0.011957, T: 65055050, Avg. loss: 0.787164\n",
      "Total training time: 354.05 seconds.\n",
      "-- Epoch 191\n",
      "Norm: 10.62, NNZs: 28695, Bias: 0.011987, T: 65397445, Avg. loss: 0.785950\n",
      "Total training time: 355.86 seconds.\n",
      "-- Epoch 192\n",
      "Norm: 10.62, NNZs: 28684, Bias: 0.012017, T: 65739840, Avg. loss: 0.785771\n",
      "Total training time: 357.68 seconds.\n",
      "-- Epoch 193\n",
      "Norm: 10.62, NNZs: 28671, Bias: 0.012043, T: 66082235, Avg. loss: 0.786364\n",
      "Total training time: 359.48 seconds.\n",
      "-- Epoch 194\n",
      "Norm: 10.62, NNZs: 28672, Bias: 0.012073, T: 66424630, Avg. loss: 0.785772\n",
      "Total training time: 361.30 seconds.\n",
      "-- Epoch 195\n",
      "Norm: 10.62, NNZs: 28666, Bias: 0.012100, T: 66767025, Avg. loss: 0.786357\n",
      "Total training time: 363.11 seconds.\n",
      "-- Epoch 196\n",
      "Norm: 10.62, NNZs: 28655, Bias: 0.012128, T: 67109420, Avg. loss: 0.784645\n",
      "Total training time: 364.93 seconds.\n",
      "-- Epoch 197\n",
      "Norm: 10.62, NNZs: 28657, Bias: 0.012158, T: 67451815, Avg. loss: 0.784708\n",
      "Total training time: 366.74 seconds.\n",
      "-- Epoch 198\n",
      "Norm: 10.62, NNZs: 28642, Bias: 0.012186, T: 67794210, Avg. loss: 0.784117\n",
      "Total training time: 368.75 seconds.\n",
      "-- Epoch 199\n",
      "Norm: 10.62, NNZs: 28638, Bias: 0.012215, T: 68136605, Avg. loss: 0.784694\n",
      "Total training time: 370.84 seconds.\n",
      "-- Epoch 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 10.62, NNZs: 28619, Bias: 0.012242, T: 68479000, Avg. loss: 0.784178\n",
      "Total training time: 373.02 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=10,\n",
       "       class_weight={0: 1, 1: 18.951239977624464}, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='hinge', max_iter=200, n_iter=None, n_jobs=-1, penalty='l1',\n",
       "       power_t=0.5, random_state=42, shuffle=False, tol=None, verbose=2,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals_results = {}\n",
    "num_boost_round=3000\n",
    "early_stopping_rounds=200\n",
    "feval=None\n",
    "\n",
    "model = SGDClassifier(**params)\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "predicted = model.predict(X_validation)\n",
    "print(\"ROC AUC score:\",roc_auc_score(Y_validation, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Save(model,\"sgd_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = scipy.sparse.load_npz(\"test_sparse_matrix_after_scale.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = model.predict(test_data)\n",
    "print(Y_test.max())\n",
    "print(Y_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(Y_test)\n",
    "predictions.to_csv(\"solution_sgd.csv\",header=None, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
