{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Parsing and Preparing for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json \n",
    "from functools import reduce\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "import os.path\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA, IncrementalPCA, SparsePCA, TruncatedSVD\n",
    "import scipy.sparse\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "sns.set(style=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spr_chunk_fn = \"sparse_folds/dspr{!s}.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = None\n",
    "rare_key_threshold = 10\n",
    "\n",
    "n_components = 1000\n",
    "nfolds = 100\n",
    "data_folder = 'data/'\n",
    "model_folder = \"models/\"\n",
    "raw_dataset_filename = model_folder+'raw_dataset.pkl'\n",
    "train_dataset_filename = model_folder+'train_dataset.pkl'\n",
    "test_dataset_filename = model_folder+'test_dataset.pkl'\n",
    "\n",
    "label_encoder_fn = model_folder + \"label_encoder.pkl\"\n",
    "\n",
    "target_name = 'target'\n",
    "test_index_name = 'tst_index'\n",
    "\n",
    "vk1_fn = model_folder+'vk1.pkl'\n",
    "vk2_fn = model_folder+'vk2.pkl'\n",
    "vk3_fn = model_folder+'vk3.pkl'\n",
    "\n",
    "\n",
    "cross_keys_fn = model_folder+'cross_keys.pkl'\n",
    "js1_keys_fn = model_folder+'js1_keys.pkl'\n",
    "js2_keys_fn = model_folder+'js2_keys.pkl'\n",
    "js3_keys_fn = model_folder+'js3_keys.pkl'\n",
    "keys_count_fn = model_folder+'keys_count.pkl'\n",
    "value_keys_fn = model_folder+'value_keys.pkl'\n",
    "target_fn = model_folder+'target.pkl'\n",
    "\n",
    "scaler_fn = model_folder+'scaler.pkl'\n",
    "svd_fn = model_folder+'svd.pkl'\n",
    "\n",
    "column_names = ['cat1','cat2','cat3','cat4','cat5','dtm','dts','em']\n",
    "\n",
    "train_data_fn = model_folder+'train_data.pkl'\n",
    "test_data_fn = model_folder+'test_data.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folds_folder = \"folds_train/\"\n",
    "test_folds_folder = \"folds_test/\"\n",
    "\n",
    "weight_multiplier_fn = model_folder+\"weight_multiplier.pkl\"\n",
    "json_metas_fn = model_folder+\"json_metas.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load(filename):\n",
    "    if os.path.isfile(filename):\n",
    "        return joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save(obj, filename):\n",
    "    joblib.dump(obj, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kill_thread(thread):\n",
    "    import ctypes\n",
    "    \n",
    "    id = thread.ident\n",
    "    code = ctypes.pythonapi.PyThreadState_SetAsyncExc(\n",
    "        ctypes.c_long(id),\n",
    "        ctypes.py_object(SystemError)\n",
    "    )\n",
    "    if code == 0:\n",
    "        raise ValueError('invalid thread id')\n",
    "    elif code != 1:\n",
    "        ctypes.pythonapi.PyThreadState_SetAsyncExc(\n",
    "            ctypes.c_long(id),\n",
    "            ctypes.c_long(0)\n",
    "        )\n",
    "        raise SystemError('PyThreadState_SetAsyncExc failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jobs_manager():\n",
    "    from IPython.lib.backgroundjobs import BackgroundJobManager\n",
    "    from IPython.core.magic import register_line_magic\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    jobs = BackgroundJobManager()\n",
    "\n",
    "    @register_line_magic\n",
    "    def job(line):\n",
    "        ip = get_ipython()\n",
    "        jobs.new(line, ip.user_global_ns)\n",
    "\n",
    "    return jobs\n",
    "\n",
    "def get_chunks(sequence, count):\n",
    "    count = min(count, len(sequence))\n",
    "    chunks = [[] for _ in range(count)]\n",
    "    for index, item in enumerate(sequence):\n",
    "        chunks[index % count].append(item) \n",
    "    return chunks\n",
    "\n",
    "def log_progress(sequence, every=None, size=None):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = size / 200     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{index} / ?'.format(index=index)\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{index} / {size}'.format(\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = str(index or '?')\n",
    "\n",
    "jobs = jobs_manager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_metas = Load(json_metas_fn)\n",
    "\n",
    "v1 = json_metas[0][\"vectorizer\"]\n",
    "v2 = json_metas[1][\"vectorizer\"]\n",
    "v3 = json_metas[2][\"vectorizer\"]\n",
    "\n",
    "label_encoder = Load(label_encoder_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpsers for sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stayOnlyKeys(keys, dictionary):\n",
    "    for key in list(dictionary.keys()):\n",
    "        if key not in keys:\n",
    "            del dictionary[key]\n",
    "    return dictionary\n",
    "\n",
    "def json_parse(text, keys):\n",
    "    return stayOnlyKeys(keys, json.loads(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def parse_fold(i, folder):\n",
    "    print(\"Loading fold:\",i)\n",
    "    dfi_fn = folder+\"dfi{!s}.pkl\".format(i)\n",
    "    df = Load(dfi_fn)\n",
    "#     print(\"df.info before i:\",i,df.info())\n",
    "    \n",
    "    df['cat_1'] = np.where(df['cat_feature'] == 1, 1, 0)\n",
    "    df['cat_2'] = np.where(df['cat_feature'] == 2, 1, 0)\n",
    "    df['cat_3'] = np.where(df['cat_feature'] == 3, 1, 0)\n",
    "    df['cat_4'] = np.where(df['cat_feature'] == 4, 1, 0)\n",
    "    df['cat_5'] = np.where(df['cat_feature'] == 5, 1, 0)\n",
    "#     df = df.drop(['cat_feature'], axis=1)\n",
    "    df['entries'] = df.groupby('id').size()\n",
    "    \n",
    "    print(\"Parsing jsons:\",i)\n",
    "    for meta in json_metas:\n",
    "        print(\"Parsing:\",meta[\"column\"],\"Fold:\",i)\n",
    "        df[meta[\"column\"]] = df[meta[\"column\"]].apply(lambda text: json_parse(text, meta[\"important_keys\"]))\n",
    "    \n",
    "    #we need to place id column at the end of dataframe\n",
    "    col_at_end = [\"id\"]\n",
    "    df = df[[c for c in df if c not in col_at_end]+[c for c in col_at_end if c in df]]\n",
    "    \n",
    "    print(\"Rewriting fold:\",i)\n",
    "    dfi_fn = folder+\"parsed_dfi{!s}.pkl\".format(i)\n",
    "    \n",
    "#     print(\"df.info after i:\",i,df.info())\n",
    "    \n",
    "    Save(df,dfi_fn)\n",
    "\n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "def parse_train_fold(i):\n",
    "    global train_folds_folder\n",
    "    \n",
    "    parse_fold(i,train_folds_folder)\n",
    "    \n",
    "def parse_test_fold(i):\n",
    "    global test_folds_folder\n",
    "    parse_fold(i, test_folds_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job # 0 in a separate thread.\n",
      "Starting job # 2 in a separate thread.\n",
      "Starting job # 3 in a separate thread.\n",
      "Starting job # 4 in a separate thread.\n",
      "Starting job # 5 in a separate thread.\n",
      "Starting job # 6 in a separate thread.\n",
      "Starting job # 7 in a separate thread.\n",
      "Starting job # 8 in a separate thread.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d25b4f2e7931403f8e107588c1235ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=13)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d20467bb599447db395f3a29382832c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=13)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a9670f207a4cf58545713d59f72dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=13)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0b5f3b1dc844ff98f13ea7e03f0918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=12)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc55a5ea777417cba934a7fb5c84745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=12)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4544094d11d84fc581443a868a35fcf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=13)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca5e39e4b514434a3cdedcf47a48a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=12)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79fb7f41aa8343bc94616fe7d990dae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=12)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fold: 0\n",
      "Loading fold: 1\n",
      "Loading fold: 3\n",
      "Loading fold: 2\n",
      "Loading fold: 4\n",
      "Loading fold: 6\n",
      "Loading fold: 5\n",
      "Loading fold: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aavdeev/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: FutureWarning: 'id' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing jsons: 5\n",
      "Parsing: json3 Fold: 5\n",
      "Parsing: json1 Fold: 5\n",
      "Parsing jsons: 7\n",
      "Parsing: json3 Fold: 7\n",
      "Parsing: json1 Fold:Parsing jsons: 4\n",
      "Parsing: json3 Fold: 7\n",
      " 4\n",
      "Parsing: json2 Fold: 5\n",
      "Parsing jsons: 1\n",
      "Parsing: json3 Fold: 1\n",
      "Parsing jsons: 6\n",
      "Parsing: json3 Fold: 6\n",
      "Parsing: json1 Fold: 4\n",
      "Parsing jsons: 0\n",
      "Parsing: json3 Fold: 0\n",
      "Parsing: json1 Fold: 1\n",
      "Parsing: json1 Fold: 6\n",
      "Parsing: json1 Fold: 0\n",
      "Parsing: json2 Fold: 7\n",
      "Parsing: json2 Fold: 4\n",
      "Parsing: json2 Fold: 1\n",
      "Parsing: json2 Fold: 0\n",
      "Parsing: json2 Fold: 6\n",
      "Parsing jsons: 2\n",
      "Parsing: json3 Fold: 2\n",
      "Rewriting fold: 5\n",
      "Loading fold: 13\n",
      "Parsing: json1 Fold: 2\n",
      "Rewriting fold: 7\n",
      "Loading fold: 15\n",
      "Parsing: json2 Fold: 2\n",
      "Rewriting fold: 1\n",
      "Rewriting fold: 4\n",
      "Loading fold: 9\n",
      "Rewriting fold: 0\n",
      "Rewriting fold: 6\n",
      "Loading fold: 12\n",
      "Loading fold: 8\n",
      "Loading fold: 14\n",
      "Rewriting fold: 2\n",
      "Parsing jsons: 3\n",
      "Parsing: json3 Fold: 3\n",
      "Parsing: json1 Fold: 3\n",
      "Loading fold: 10\n",
      "Parsing: json2 Fold: 3\n",
      "Rewriting fold: 3\n",
      "Loading fold: 11\n",
      "Parsing jsons: 13\n",
      "Parsing: json3 Fold: 13\n",
      "Parsing: json1 Fold: 13\n",
      "Parsing: json2 Fold: 13\n",
      "Rewriting fold: 13\n",
      "Parsing jsons: 15\n",
      "Parsing: json3 Fold: 15\n",
      "Parsing jsons: 12\n",
      "Parsing: json3 Fold: 12\n",
      "Loading fold: 21\n",
      "Parsing: json1 Fold: 15\n",
      "Parsing: json1 Fold: 12\n",
      "Parsing jsons: 9\n",
      "Parsing: json3 Fold: 9\n",
      "Parsing: json2 Fold: 15\n",
      "Parsing: json1 Fold: 9\n",
      "Parsing: json2 Fold: 12\n",
      "Parsing jsons: 14\n",
      "Parsing: json3 Fold: 14\n",
      "Parsing: json1 Fold: 14\n",
      "Parsing: json2 Fold: 9\n",
      "Rewriting fold: 15\n",
      "Parsing: json2 Fold: 14\n",
      "Loading fold: 23\n",
      "Rewriting fold: 12\n",
      "Loading fold: 20\n",
      "Rewriting fold: 9\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for chunk in get_chunks(range(0,nfolds), 8):\n",
    "    %job [parse_train_fold(index) for index in log_progress(chunk, every=1)]    \n",
    "\n",
    "for thread in jobs.running:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# def add_cuid_column(df):\n",
    "#     global label_encoder\n",
    "    \n",
    "#     df['cuid'] = df.index\n",
    "#     df = df.reset_index(drop=True)\n",
    "#     df['cuid'] = label_encoder.transform(df['cuid'])\n",
    "    \n",
    "#     return df\n",
    "\n",
    "def get_mask(df):\n",
    "    mask = collections.defaultdict(list)\n",
    "\n",
    "    #last column is the index\n",
    "    for i,v in enumerate(df.values[:,-1]):\n",
    "        mask[v].append(i)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def group_chunk(A,mask):\n",
    "    mask0 = list(mask.values())[0]\n",
    "    \n",
    "#     print(\"chunk i:\",i,\",matrix\",A[mask0,:])\n",
    "    cgr_sum = csr_matrix(A[mask0,:].sum(axis=0))\n",
    "    cgr_mean = csr_matrix(A[mask0,:].mean(axis=0))\n",
    "    cgr_max = csr_matrix(A[mask0,:].max(axis=0))\n",
    "    \n",
    "    t = 0\n",
    "    for k in mask:\n",
    "        if t != 0:\n",
    "#             print('k!=0')\n",
    "            cgr_sum = vstack([\n",
    "                cgr_sum,\n",
    "                csr_matrix(A[mask[k],:].sum(axis=0))\n",
    "            ])\n",
    "            cgr_mean = vstack([\n",
    "                cgr_mean,\n",
    "                csr_matrix(A[mask[k],:].mean(axis=0))\n",
    "            ])        \n",
    "            cgr_max = vstack([\n",
    "                cgr_max,\n",
    "                csr_matrix(A[mask[k],:].max(axis=0))\n",
    "            ])\n",
    "        t= t+1\n",
    "\n",
    "    return hstack([cgr_sum,cgr_mean,cgr_max]).tocsr()    \n",
    "    \n",
    "def save_sparse_chunk(data,i,folder): \n",
    "    scipy.sparse.save_npz(folder+\"dspr{!s}.npz\".format(i), data)\n",
    "    \n",
    "def load_sparse_chunk(i,folder):\n",
    "    return scipy.sparse.load_npz(folder+\"dspr{!s}.npz\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack, hstack, csr_matrix\n",
    "from scipy import sparse\n",
    "import gc\n",
    "\n",
    "def sparse(i, folder):\n",
    "    global v1\n",
    "    global v2\n",
    "    global v3\n",
    "    \n",
    "    print(\"Loading chunk:\",i)\n",
    "    df = Load(folder+\"parsed_dfi{!s}.pkl\".format(i))\n",
    "#     print(\"df.shape\",df.info())\n",
    "#     df = add_cuid_column(df)\n",
    "    \n",
    "    print('Counting mask dictionary:',i)\n",
    "    mask = get_mask(df)\n",
    "       \n",
    "    print(\"Sparsing and transforming chunk:\",i)\n",
    "    \n",
    "    j1 = v1.transform(df['json1'])\n",
    "    j2 = v2.transform(df['json2'])\n",
    "    j3 = v3.transform(df['json3'])\n",
    "    \n",
    "    df_c = df.drop([\"json1\",\"json2\",\"json3\"], axis=1)\n",
    "#     df_c = df[['cat_1','cat_2','cat_3','cat_4','cat_5','dt_diff','entries','id']]\n",
    "    df_cs = csr_matrix(df_c.to_sparse().to_coo())\n",
    "\n",
    "    print(\"Concant chunk:\",i)\n",
    "    A = hstack([j1,j2,j3,df_cs]).tocsr()\n",
    "\n",
    "    print(\"Groupby chunk:\",i)\n",
    "    sparse_data = group_chunk(A, mask)\n",
    "    \n",
    "    print(\"Saving sparsed chunk:\",i)\n",
    "    save_sparse_chunk(sparse_data,i,folder)\n",
    "    print(\"Saved chunk:\",i)\n",
    "    del df\n",
    "    del mask\n",
    "    del df_c\n",
    "    del df_cs\n",
    "    del j1\n",
    "    del j2\n",
    "    del j3\n",
    "    del A\n",
    "    del sparse_data\n",
    "    gc.collect()\n",
    "\n",
    "def sparse_train_fold(i):\n",
    "    global train_folds_folder\n",
    "    \n",
    "    sparse(i,train_folds_folder)\n",
    "    \n",
    "def sparse_test_fold(i):\n",
    "    global test_folds_folder\n",
    "    \n",
    "    sparse(i,test_folds_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for chunk in get_chunks(range(0,nfolds), 8):\n",
    "    %job [sparse_train_fold(index) for index in log_progress(chunk, every=1)]\n",
    "    \n",
    "for thread in jobs.running:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collections folds to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import gc\n",
    "from scipy.sparse import coo_matrix, hstack, vstack\n",
    "\n",
    "sparse_matrix = load_sparse_chunk(0,train_folds_folder)\n",
    "\n",
    "for i in range(1,nfolds):\n",
    "    print(i)\n",
    "    next_chunk = load_sparse_chunk(i,train_folds_folder)\n",
    "    print(\"next_chunk.shape\",next_chunk.shape)\n",
    "    sparse_matrix = vstack([sparse_matrix, next_chunk])\n",
    "    print(\"sparse_matrix.shape\",sparse_matrix.shape)\n",
    "\n",
    "scipy.sparse.save_npz(\"train_sparse_matrix_before_scale.npz\", sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for chunk in get_chunks(range(0,nfolds), 8):\n",
    "    %job [parse_test_fold(index) for index in log_progress(chunk, every=1)]    \n",
    "    \n",
    "for thread in jobs.running:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for chunk in get_chunks(range(0,nfolds), 8):\n",
    "    %job [sparse_test_fold(index) for index in log_progress(chunk, every=1)]\n",
    "    \n",
    "for thread in jobs.running:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import gc\n",
    "from scipy.sparse import coo_matrix, hstack, vstack\n",
    "\n",
    "test_sparse_matrix = load_sparse_chunk(0,test_folds_folder)\n",
    "\n",
    "for i in range(1,nfolds):\n",
    "    print(i)\n",
    "    next_chunk = load_sparse_chunk(i,test_folds_folder)\n",
    "    test_sparse_matrix = vstack([test_sparse_matrix, next_chunk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz(\"test_sparse_matrix_before_scale.npz\", test_sparse_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_sparse_matrix = sparse_matrix\n",
    "all_sparse_matrix = vstack([all_sparse_matrix, test_sparse_matrix])\n",
    "scipy.sparse.save_npz(\"all_sparse_matrix_before_scale.npz\", sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "scaler = StandardScaler(with_mean=False).fit(all_sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Save(scaler,'scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sparse_matrix = scaler.transform(sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_sparse_matrix = scaler.transform(test_sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scipy.sparse.save_npz(\"train_sparse_matrix_after_scale.npz\", sparse_matrix)\n",
    "scipy.sparse.save_npz(\"test_sparse_matrix_after_scale.npz\", test_sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_sparse_matrix = scaler.transform(all_sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scipy.sparse.save_npz(\"all_sparse_matrix_after_scale.npz\", all_sparse_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sparse_matrix = scipy.sparse.load_npz(\"all_sparse_matrix_after_scale.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(\n",
    "    n_components=n_components,\n",
    "    n_iter=5,\n",
    "    random_state=42,\n",
    "#     algorithm = \"arpack\",\n",
    "#     tol\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "svd = svd.fit(all_sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Save(svd,svd_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sparse_matrix = scipy.sparse.load_npz(\"train_sparse_matrix_after_scale.npz\")\n",
    "data = svd.transform(sparse_matrix)\n",
    "Save(data, train_data_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_sparse_matrix = scipy.sparse.load_npz(\"test_sparse_matrix_after_scale.npz\")\n",
    "test_data = svd.transform(test_sparse_matrix)\n",
    "Save(test_data, test_data_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
